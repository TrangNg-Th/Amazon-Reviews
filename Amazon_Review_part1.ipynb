{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# **Introduction**\n",
    "\n",
    "In this notebook, we explore different available Machine Learning techniques as well as Deep Leearning techniques for the task of Sentiment Classification. The data we used are from Amazon Fine Food Reviews data set extracted from [Kaggle](https://www.kaggle.com/snap/amazon-fine-food-reviews). This notebook is the first part of our journey.\n",
    "\n",
    "\n",
    "Since the dataset is quite voluminous (500k reviews), I've only imported 10% of the dataset. \n",
    "\n",
    "# **Importing Packages**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import os  # Get directory\r\n",
    "import re\r\n",
    "import pandas as pd \r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import seaborn as sns  # Pretty plots :)\r\n",
    "import ipywidgets as widgets  # Interactive plot x)\r\n",
    "import nltk\r\n",
    "from nltk import FreqDist\r\n",
    "from nltk.stem import WordNetLemmatizer\r\n",
    "from nltk.corpus import stopwords\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "# Set the theme\r\n",
    "sns.set_theme()\r\n",
    "\r\n",
    "# Print every output\r\n",
    "from IPython.core.interactiveshell import InteractiveShell\r\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\r\n",
    "\r\n",
    "# Retrieve current directory\r\n",
    "repo = os.getcwd()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Load and check data\r\n",
    "df = pd.read_csv(repo + '/Reviews_small.csv', index_col='Id')\r\n",
    "df.head(3)  \r\n",
    "\r\n",
    "# Check data types\r\n",
    "df.info()\r\n",
    "\r\n",
    "print('\\n Shape of data', df.shape)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>B001GVISJM</td>\n",
       "      <td>A18ECVX2RJ7HUE</td>\n",
       "      <td>willie \"roadie\"</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1288915200</td>\n",
       "      <td>fresh and greasy!</td>\n",
       "      <td>good flavor! these came securely packed... the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>B001GVISJM</td>\n",
       "      <td>A2MUGFV2TDQ47K</td>\n",
       "      <td>Lynrie \"Oh HELL no\"</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1268352000</td>\n",
       "      <td>Strawberry Twizzlers - Yummy</td>\n",
       "      <td>The Strawberry Twizzlers are my guilty pleasur...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ProductId          UserId          ProfileName  HelpfulnessNumerator  \\\n",
       "Id                                                                          \n",
       "4   B000UA0QIQ  A395BORC6FGVXV                 Karl                     3   \n",
       "14  B001GVISJM  A18ECVX2RJ7HUE      willie \"roadie\"                     2   \n",
       "15  B001GVISJM  A2MUGFV2TDQ47K  Lynrie \"Oh HELL no\"                     4   \n",
       "\n",
       "    HelpfulnessDenominator  Score        Time                       Summary  \\\n",
       "Id                                                                            \n",
       "4                        3      2  1307923200                Cough Medicine   \n",
       "14                       2      4  1288915200             fresh and greasy!   \n",
       "15                       5      5  1268352000  Strawberry Twizzlers - Yummy   \n",
       "\n",
       "                                                 Text  \n",
       "Id                                                     \n",
       "4   If you are looking for the secret ingredient i...  \n",
       "14  good flavor! these came securely packed... the...  \n",
       "15  The Strawberry Twizzlers are my guilty pleasur...  "
      ]
     },
     "metadata": {},
     "execution_count": 3
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 57507 entries, 4 to 568442\n",
      "Data columns (total 9 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   ProductId               57507 non-null  object\n",
      " 1   UserId                  57507 non-null  object\n",
      " 2   ProfileName             57506 non-null  object\n",
      " 3   HelpfulnessNumerator    57507 non-null  int64 \n",
      " 4   HelpfulnessDenominator  57507 non-null  int64 \n",
      " 5   Score                   57507 non-null  int64 \n",
      " 6   Time                    57507 non-null  int64 \n",
      " 7   Summary                 57504 non-null  object\n",
      " 8   Text                    57507 non-null  object\n",
      "dtypes: int64(4), object(5)\n",
      "memory usage: 4.4+ MB\n",
      "\n",
      " Shape of data (57507, 9)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The dataset contains ~50k reviews from Amazon, with 9 different columns : ProductId, UserId, ProfileName,... The column Score is our target column. Note that the column Score is **ordinal**. Our goal here is to predict the score of each reviews. It's a classification task.\n",
    "\n",
    "The columns Helpxxx don't contain useful information for our task since they are given after the reviews have been made and not relevant to classify the reviews.\n",
    "\n",
    "Recall that we want to predict the score of the item based on their reviews : texts or summaries. We can remove all the Id columns as well (after EDA)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Clean up data\n",
    "\n",
    "In this section, we will convert columns into their expected format, and remove the columns that we will not use, and remove empty values. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Modify data types Summary/ Text / Score\r\n",
    "df.loc[:,'Summary'] = df['Summary'].astype('string')\r\n",
    "df.loc[:,'Text'] = df['Text'].astype('string')\r\n",
    "\r\n",
    "# Convert time to datetime format\r\n",
    "print('\\n Data after converting Time to datetime format')\r\n",
    "df['Time'] = pd.to_datetime(df['Time'], unit='s')\r\n",
    "df.head(3)\r\n",
    "\r\n",
    "# Check percentage of missing values\r\n",
    "df.isna().sum().sort_values(ascending=False)/df.shape[0]\r\n",
    "# The missing values are less than 5%, we can safely remove them out\r\n",
    "df.dropna(inplace=True)\r\n",
    "\r\n",
    "# Remove helpxxx columns\r\n",
    "df.drop(['HelpfulnessNumerator', 'HelpfulnessDenominator', 'ProfileName'], axis=1, inplace=True)\r\n",
    "\r\n",
    "# Categorical/ Numerical features\r\n",
    "cat = df.select_dtypes(include='O').columns\r\n",
    "num = df.select_dtypes(exclude='O').columns\r\n",
    "\r\n",
    "\r\n",
    "# Print out categorifal features/ numerical features\r\n",
    "print('Categorical features are', cat.to_list())\r\n",
    "print('Numerical features are', num.to_list())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      " Data after converting Time to datetime format\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2011-06-13</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>B001GVISJM</td>\n",
       "      <td>A18ECVX2RJ7HUE</td>\n",
       "      <td>willie \"roadie\"</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2010-11-05</td>\n",
       "      <td>fresh and greasy!</td>\n",
       "      <td>good flavor! these came securely packed... the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>B001GVISJM</td>\n",
       "      <td>A2MUGFV2TDQ47K</td>\n",
       "      <td>Lynrie \"Oh HELL no\"</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2010-03-12</td>\n",
       "      <td>Strawberry Twizzlers - Yummy</td>\n",
       "      <td>The Strawberry Twizzlers are my guilty pleasur...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ProductId          UserId          ProfileName  HelpfulnessNumerator  \\\n",
       "Id                                                                          \n",
       "4   B000UA0QIQ  A395BORC6FGVXV                 Karl                     3   \n",
       "14  B001GVISJM  A18ECVX2RJ7HUE      willie \"roadie\"                     2   \n",
       "15  B001GVISJM  A2MUGFV2TDQ47K  Lynrie \"Oh HELL no\"                     4   \n",
       "\n",
       "    HelpfulnessDenominator  Score       Time                       Summary  \\\n",
       "Id                                                                           \n",
       "4                        3      2 2011-06-13                Cough Medicine   \n",
       "14                       2      4 2010-11-05             fresh and greasy!   \n",
       "15                       5      5 2010-03-12  Strawberry Twizzlers - Yummy   \n",
       "\n",
       "                                                 Text  \n",
       "Id                                                     \n",
       "4   If you are looking for the secret ingredient i...  \n",
       "14  good flavor! these came securely packed... the...  \n",
       "15  The Strawberry Twizzlers are my guilty pleasur...  "
      ]
     },
     "metadata": {},
     "execution_count": 4
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Summary                   0.000052\n",
       "ProfileName               0.000017\n",
       "ProductId                 0.000000\n",
       "UserId                    0.000000\n",
       "HelpfulnessNumerator      0.000000\n",
       "HelpfulnessDenominator    0.000000\n",
       "Score                     0.000000\n",
       "Time                      0.000000\n",
       "Text                      0.000000\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 4
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Categorical features are ['ProductId', 'UserId']\n",
      "Numerical features are ['Score', 'Time', 'Summary', 'Text']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Description of data\n",
    " \n",
    " Our data set contains $\\approx$ 50k observations, in which each observation is a review left by a customer on a product at a specific moment. The key access to the table is the Id column (unique). There are 9 features (columns) in the table, where each column is self-explanatory: \n",
    "\n",
    "    ProductId: helps to identify the product\n",
    "    UserId: helps to identify the customer\n",
    "    Profile Name: Name chosen by user (we will remove this column since we already had access to UserId, which is a better indentifier of each user. *We noticed that some different users can have the same ProfileName*)\n",
    "    Summary: summarized version of the review\n",
    "    Text: Detailed version of the review\n",
    "    Score: Our targeted discrete feature, score from 1-5\n",
    "    Time: The time of the review\n",
    "    \n",
    "\n",
    "Some observations are missing, but this number is minimal compared to the data size, therefore we removed them from the table.\n",
    "\n",
    "It is also interesting to point out that the table doesn't consist of unique user giving reviews to an unique product. We can find one product being rated by different users, as well as one user giving reviews to different products (*number of UserId and ProductId are $\\leq$ than number of observations*). This suggests us to explore if there's common points between the users or the products.\n",
    "\n",
    "# Explanatory Data Analysis\n",
    "\n",
    "Sometimes, it's overwhelming to start the data analysis task. Don't worry, I got you. When there's a new dataset. Instead of approaching it with statistics tools, just give in to all the first questions that you have in mind. Be curious, write down all the questions you'd like to ask your dataset before starting to code. It's always helped me to organize my workflow in EDA.\n",
    "\n",
    "For instant, this dataset is quite self-explanatory, but also very mysterious, I'd love to know : \n",
    "\n",
    "1. What is the distribution of the scores ? Do we often have more good reviews than bad? (I expect that the reviews will be mostly good, since Amazon has a good reputation. If so, this may be problematic for us, because our predictor will perform poorly on the bad reviews).\n",
    "\n",
    "2. The reviews are often short, and may contain emojis, excessive punctuation, poor grammars,... This means that we will need to clean up our reviews a little bit before doing any classification.\n",
    "\n",
    "(Other not too important questions)\n",
    "\n",
    "\n",
    "\n",
    "3. Do we have any groups of users who often give the same scores ? (Maybe someone who always gives good feedback ?)\n",
    "\n",
    "4. What about our Products, do we have any good on average products, or bad on average products?\n",
    "\n",
    "\n",
    "\n",
    "Those are my first questions in mind, let's try to aswer them one by one. How about you, do you have any additional ones ? \n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Check how the scores are distributed\r\n",
    "plt.figure(figsize=(7, 7))\r\n",
    "sns.histplot(df['Score'], bins=5)\r\n",
    "plt.title('Number of observations in each Score category')\r\n",
    "plt.show();"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We clearly have too many good reviews. This problem is called imbalanced class. We should be careful with our choice of models to deal with this. XGBOOST may help us to overcome this problem."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Check our users and our products\r\n",
    "df.groupby(['UserId'])['Score'].mean().head(3) # Check average scores given by each UserId\r\n",
    "df.groupby(['UserId'])['Score'].count().head(3)  # Check number of reviews given per user\r\n",
    "\r\n",
    "# Same but for product\r\n",
    "df.groupby('ProductId')['Score'].mean().head(3)\r\n",
    "df.groupby(['ProductId'])['Score'].count().head(3)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "UserId\n",
       "#oc-R12KPBODL2B5ZD    1.0\n",
       "#oc-R1522DF2LUL4G1    1.0\n",
       "#oc-R1BKC1B35FFB0     3.0\n",
       "Name: Score, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 6
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "UserId\n",
       "#oc-R12KPBODL2B5ZD    1\n",
       "#oc-R1522DF2LUL4G1    1\n",
       "#oc-R1BKC1B35FFB0     1\n",
       "Name: Score, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 6
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ProductId\n",
       "141278509X    5.0\n",
       "9376674501    5.0\n",
       "B00004RBDW    4.0\n",
       "Name: Score, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 6
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ProductId\n",
       "141278509X     1\n",
       "9376674501     1\n",
       "B00004RBDW    31\n",
       "Name: Score, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Some products have only 1 review, which may turn out to be hard for us to dermine the score. (When taking a small part of our original dataset, I've chosen to retrieve all reviews for a given product). Since we are interested only in the reviews, I will remove all Id & time columns out of our dataset."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The block code below allows us to look at the distribution of scores within each product."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "%matplotlib widget\r\n",
    "#Prod = widgets.Dropdown(options = sorted(list(set(df['ProductId']))))\r\n",
    "Prod = list(set(df['ProductId']))\r\n",
    "# Check if we have a set of products who always receive a certain score\r\n",
    "def bar_plot(prod):\r\n",
    "    print(f'ProductId {prod}')\r\n",
    "    df_plot = df.groupby(['ProductId','Score'])['Score'].count().rename('Count', axis=1).reset_index()  \r\n",
    "    df_plot = df_plot[df_plot['ProductId']==prod]\r\n",
    "    df_plot['Count'].astype(int)\r\n",
    "    \r\n",
    "    plt.figure(figsize=(3, 3))\r\n",
    "    sns.barplot(x='Score', y='Count', data=df_plot)\r\n",
    "    plt.title('Distribution of score')\r\n",
    "    plt.show();\r\n",
    "    \r\n",
    "widgets.interact(bar_plot,  prod=Prod)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "96c7f75e47a24659ade1a89dc3ae01a3"
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='prod', options=('B000GLUEFO', 'B003BN7DLW', 'B001ELL6VG', 'B004G5Z…"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<function __main__.bar_plot(prod)>"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Remove columns\r\n",
    "df.drop(['ProductId', 'UserId', 'Time',], axis=1, inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Handling raw texts is hard for any algorithm, therefor we need to have preliminary steps to clean up the raw string that we obtained from the reivews. Some of the questions that may help us to grab some general statistics are :\n",
    "\n",
    "    1. How many unique words are there in the corpus provided?\n",
    "    2. What are the most common strings ? \n",
    "    3. How do longest/shortest strings look like?\n",
    "    4. Are there any weird expressions (url, wrongly spelled words,..)?\n",
    "\n",
    "The cell below will help us to see what are most common strings in the corpus, and how do the longest/shortest strings look like"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Check number of words\r\n",
    "train_string = ' '.join(df['Text'])\r\n",
    "splits = train_string.split() \r\n",
    "print('Number of words (punctuation included):', len(splits))\r\n",
    "print('Number of unique words(punct included):', len(set(splits)))\r\n",
    "\r\n",
    "# Check the most common words\r\n",
    "freq_splits = FreqDist(splits)\r\n",
    "print('_'*80)\r\n",
    "print('20 most common words \\n', freq_splits.most_common(20), '\\n')\r\n",
    "\r\n",
    "# Shortest words\r\n",
    "print('_'*80)\r\n",
    "print(\"Shortest words\")\r\n",
    "short = set(s for s in splits if len(s)<4)\r\n",
    "short = [(s, freq_splits[s]) for s in short]\r\n",
    "short.sort(key=lambda x:x[1], reverse=True)\r\n",
    "short[0:5]\r\n",
    "\r\n",
    "#Longest words \r\n",
    "print('_'*80)\r\n",
    "print(\"Longest words \\n\")\r\n",
    "long = set(s for s in splits if len(s)>15)\r\n",
    "long = [(s, freq_splits[s]) for s in long]\r\n",
    "long.sort(key=lambda x:x[1], reverse=True)\r\n",
    "long[0:10]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of words (punctuation included): 4624839\n",
      "Number of unique words(punct included): 157908\n",
      "________________________________________________________________________________\n",
      "20 most common words \n",
      " [('the', 165079), ('I', 140564), ('and', 124758), ('a', 117139), ('to', 100209), ('of', 80150), ('is', 71985), ('it', 62511), ('for', 52915), ('in', 51696), ('this', 48668), ('that', 40457), ('my', 36761), ('have', 33898), ('with', 33741), ('but', 33586), ('are', 32588), ('was', 31804), ('not', 28913), ('you', 27911)] \n",
      "\n",
      "________________________________________________________________________________\n",
      "Shortest words\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('the', 165079),\n",
       " ('I', 140564),\n",
       " ('and', 124758),\n",
       " ('a', 117139),\n",
       " ('to', 100209)]"
      ]
     },
     "metadata": {},
     "execution_count": 9
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "________________________________________________________________________________\n",
      "Longest words \n",
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('/>Unfortunately,', 49),\n",
       " ('disappointed.<br', 35),\n",
       " ('gastrointestinal', 24),\n",
       " ('preservatives.<br', 20),\n",
       " ('href=\"http://www.amazon.com/gp/product/B002IEZJMA\">illy', 19),\n",
       " ('Frustration-Free', 17),\n",
       " ('over-the-counter', 15),\n",
       " ('health-conscious', 14),\n",
       " ('overpowering.<br', 13),\n",
       " ('expectations.<br', 13)]"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Remarks** \n",
    "\n",
    "* In the reviews' content, 20 most common words are among the stop words (I, the, and, to,...). These words don't bring additional information to the sentiment classification (at least in the context of product reviews, we do not intend to claim that the presence of a subject in a string will not imply additional emotion intensity). However, in product reviews, we assume that these words don't convey particular meaning to the reviews, therefore we will need to remove them later. \n",
    "\n",
    "*  Hyphenated words:  (ex: Gluten-free). If we tokenise on white space or punctuation, these strings will be split into separate words. For most cases, this will conserve the gist of the sentence. If we keep hyphenated words as they are, they won’t be as common and consequently removed as rare words. (We can compare the two strategies)\n",
    "\n",
    "* There are words combined with other punctuation (some due to lack of space) ex:'preservatives..'. It would be good to separate these cases into separate words when tokenising. So probably tokenising based on white space or punctuation is a good idea.\n",
    "\n",
    "* There are websites addresses that we will need to remove\n",
    "\n",
    "* There are wrongly spelled words that repeat the same character more than twice: 'consumption......'\n",
    "\n",
    "The function below will focus on finding specific expressions in our corpus."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def find_pattern(pattern, words, freq):\r\n",
    "    \"\"\" \r\n",
    "    Input : \r\n",
    "    pattern : str of patterns we want to search for\r\n",
    "    words : list of words\r\n",
    "    freq : the frency Function which takes a list of tupples containing matched string and their frequency\"\"\"\r\n",
    "    \r\n",
    "    # Match patterns\r\n",
    "    compiled_pattern = re.compile(pattern)\r\n",
    "    matches = [w for w in words if compiled_pattern.search(w)]\r\n",
    "\r\n",
    "    # Display proportion of matcheds\r\n",
    "    print(len(matches), \r\n",
    "          'words matched, which is {:.2%} of total'.format(len(matches)/len(words)))\r\n",
    "    \r\n",
    "    # Create list of tupples\r\n",
    "    res = [(w, freq[w]) for w in set(matches)]\r\n",
    "    res.sort(key=lambda x:x[1], reverse=True)\r\n",
    "    print(f'Sample of patterns searched {res[0:10]} \\n')\r\n",
    "\r\n",
    "# Find hltml tags\r\n",
    "find_pattern(r'/?>?w*<|/>', splits, freq_splits)\r\n",
    "\r\n",
    "# Find numbers\r\n",
    "find_pattern(r'\\d', splits, freq_splits)\r\n",
    "\r\n",
    "# Find Hyphenated words\r\n",
    "find_pattern(r'\\w+-+\\w+', splits, freq_splits)\r\n",
    "\r\n",
    "# Find 'href=' patterns\r\n",
    "find_pattern(r'href\\=', splits, freq_splits)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "106842 words matched, which is 2.31% of total\n",
      "Sample of patterns searched [('/><br', 26219), ('/>I', 5399), ('/>The', 2616), ('<a', 1164), ('/>This', 1131), ('/>My', 797), ('it.<br', 794), ('/>', 742), ('/>If', 740), ('/>It', 658)] \n",
      "\n",
      "51981 words matched, which is 1.12% of total\n",
      "Sample of patterns searched [('2', 3336), ('3', 2736), ('5', 2154), ('4', 1995), ('1', 1679), ('6', 1388), ('10', 1056), ('12', 966), ('8', 816), ('100', 684)] \n",
      "\n",
      "23535 words matched, which is 0.51% of total\n",
      "Sample of patterns searched [('gluten-free', 314), ('K-Cups', 302), ('k-cups', 299), ('K-cups', 296), ('K-cup', 258), ('K-Cup', 250), ('k-cup', 240), ('2-3', 158), ('sugar-free', 132), ('3-4', 112)] \n",
      "\n",
      "1571 words matched, which is 0.03% of total\n",
      "Sample of patterns searched [('href=\"http://www.amazon.com/gp/product/B002IEZJMA\">illy', 19), ('href=\"http://www.amazon.com/gp/product/B0029XDZIK\">Coffee', 12), ('href=\"http://www.amazon.com/gp/product/B000AQPMHA\">Keurig', 9), ('href=\"http://www.amazon.com/gp/product/B004779XNW\">Green', 9), ('href=\"http://www.amazon.com/gp/product/B003AZ2ECY\">Gourmet', 8), ('href=\"http://www.amazon.com/gp/product/B004M5W7YQ\">Emerils', 8), ('href=\"http://www.amazon.com/gp/product/B003JA5KKS\">Green', 7), ('href=\"http://www.amazon.com/gp/product/B002IEVJRY\">illy', 7), ('href=\"http://www.amazon.com/gp/product/B001ELL68Y\">Tully\\'s', 7), ('href=\"http://www.amazon.com/gp/product/B001RVAWY0\">Popchips,', 5)] \n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "def find_repeatly_spelled(word):\r\n",
    "    \"\"\"Find words that contain a same character 3+ times in a row.\r\n",
    "        Return bool\r\n",
    "    \"\"\"\r\n",
    "    is_wrongly_spelled = False\r\n",
    "    for i, letter in enumerate(word):\r\n",
    "        if i > 1:\r\n",
    "            if word[i] == word[i-1] == word[i-2] and word[i].isalpha():\r\n",
    "                is_wrongly_spelled = True\r\n",
    "                break\r\n",
    "    return is_wrongly_spelled\r\n",
    "\r\n",
    "\r\n",
    "# List of repeatedly spelled words\r\n",
    "list_repeatly_spelled = [w for w in splits if find_repeatly_spelled(w)]\r\n",
    "\r\n",
    "# Print out percentage\r\n",
    "print('Percentage of wrongly spelled words')\r\n",
    "print('{} strings, that is {:.2%} of total'.format(len(list_repeatly_spelled), \r\n",
    "                                         len(list_repeatly_spelled)/len(splits)))\r\n",
    "outlaw_freq = [(w, freq_splits[w]) for w in set(list_repeatly_spelled)]\r\n",
    "outlaw_freq.sort(key=lambda x:x[1], reverse=True)\r\n",
    "print(f'Examples of weird expressions {outlaw_freq[0:10]}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Percentage of wrongly spelled words\n",
      "2723 strings, that is 0.06% of total\n",
      "Examples of weird expressions [('soooo', 86), ('sooo', 75), ('sooooo', 45), ('soooooo', 25), ('href=\"http://www.amazon.com/gp/product/B002IEZJMA\">illy', 19), ('Soooo', 13), ('href=\"http://www.amazon.com/gp/product/B0029XDZIK\">Coffee', 12), ('SOOO', 11), ('href=\"http://www.amazon.com/gp/product/B000AQPMHA\">Keurig', 9), ('href=\"http://www.amazon.com/gp/product/B004779XNW\">Green', 9)]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Remarks**\n",
    "\n",
    "* The number of words where there are html tags are of 2% of the train data set. This will not be a problem since later we will tokenise on whitespace and punctuation (including special characters). These words will \"appear\" normal. Note that words such as \"br\" should also be included in our stopwords => We need to expand our list of stopwords\n",
    "\n",
    "* There are some numbers in the reviews, but since they only take 1% of the train data, and in most case, they don't convey a particular sentiment, we will also not take them into account when tokenizing => We will remove the numbers when cleaning the text\n",
    "\n",
    "* The percentage of hyphenated words are very few ($\\leq$ 2%) if they are treated as one word, and they don't increase the tdidf matrix size, then we will include hyphenated words in our analysis, if they increase the matrix size, we will remove them as well.\n",
    "\n",
    "Below is the function to clean the text.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# Add html words tag into stop words collection\r\n",
    "stop_words = stopwords.words(\"english\")\r\n",
    "stop_words.extend(['br', 'href'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "def preprocess_string(string):\r\n",
    "    # Lower case\r\n",
    "    string = string.lower()\r\n",
    "    \r\n",
    "    # Remove html tags    \r\n",
    "    html_tag = re.compile('<.*?>')\r\n",
    "    string = re.sub(html_tag, ' ', string)\r\n",
    "\r\n",
    "    # Remove url\r\n",
    "    string = re.sub(r'http\\S+', ' ', string) \r\n",
    "    \r\n",
    "    # Remove single / double characters\r\n",
    "    string = re.sub(r'\\b\\w{1,2}\\b', ' ', string)\r\n",
    "    \r\n",
    "    # Remove words that are in stop words\r\n",
    "    string = ' '.join(w for w in string.split() if w not in stop_words)\r\n",
    "    \r\n",
    "     # Remove word that starts with \"aa\"\r\n",
    "    string = re.sub(r'^aa\\w+', ' ', string)\r\n",
    "\r\n",
    "    # Remove word that have 3+ consecutive words for ex: wooow\r\n",
    "    string = re.sub(r'\\b\\w*(\\w)\\1\\1\\w*', ' ', string)\r\n",
    "    \r\n",
    "    # Remove digits\r\n",
    "    string = re.sub(r'\\d', ' ', string)\r\n",
    "    \r\n",
    "    # Remove extra white space\r\n",
    "    string = re.sub(r'[\\s]+', ' ', string) \r\n",
    "\r\n",
    "    # Remove punctuation\r\n",
    "    string = re.sub(r'[^\\w\\s]',' ', string)\r\n",
    "    \r\n",
    "    # Replace '-' with a space \r\n",
    "    string = re.sub(r\"\\-\", ' ', string) #\r\n",
    "\r\n",
    "    # Remove extra ''\r\n",
    "    string = re.sub(r\"\\'+\", '', string) \r\n",
    "\r\n",
    "    \r\n",
    "    return(string)\r\n",
    "\r\n",
    "def lemmatize_string(string):\r\n",
    "    lem=WordNetLemmatizer()\r\n",
    "    prep_string = preprocess_string(string)\r\n",
    "    string = ' '.join(lem.lemmatize(w, pos='v') for w in prep_string.split())\r\n",
    "    return(string)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# Clean the text\r\n",
    "df['Summary_prep'] = df['Summary'].apply(lemmatize_string)\r\n",
    "print('Done cleaning Summary!'+'.'*80)\r\n",
    "\r\n",
    "df['Text_prep'] = df['Text'].apply(lemmatize_string)\r\n",
    "print('Done cleaning Text!'+'.'*80)\r\n",
    "\r\n",
    "# Export cleaned data\r\n",
    "df.to_csv(repo+'/Reviews_cleaned.csv', encoding='utf-8', index=False)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Done cleaning Summary!................................................................................\n",
      "Done cleaning Text!................................................................................\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# Prepare data set\r\n",
    "# Import cleaned data\r\n",
    "df_new = pd.read_csv(repo + '/Reviews_cleaned.csv')\r\n",
    "df_new.dropna(inplace=True)\r\n",
    "\r\n",
    "# Load and check data\r\n",
    "df_new.head(3)  \r\n",
    "\r\n",
    "# Check data types\r\n",
    "df_new.info()\r\n",
    "\r\n",
    "print('\\n Shape of data', df_new.shape)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary_prep</th>\n",
       "      <th>Text_prep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>cough medicine</td>\n",
       "      <td>look secret ingredient robitussin believe find...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>fresh and greasy!</td>\n",
       "      <td>good flavor! these came securely packed... the...</td>\n",
       "      <td>fresh greasy</td>\n",
       "      <td>good flavor come securely pack fresh delicious...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Strawberry Twizzlers - Yummy</td>\n",
       "      <td>The Strawberry Twizzlers are my guilty pleasur...</td>\n",
       "      <td>strawberry twizzlers yummy</td>\n",
       "      <td>strawberry twizzlers guilty pleasure yummy six...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Score                       Summary  \\\n",
       "0      2                Cough Medicine   \n",
       "1      4             fresh and greasy!   \n",
       "2      5  Strawberry Twizzlers - Yummy   \n",
       "\n",
       "                                                Text  \\\n",
       "0  If you are looking for the secret ingredient i...   \n",
       "1  good flavor! these came securely packed... the...   \n",
       "2  The Strawberry Twizzlers are my guilty pleasur...   \n",
       "\n",
       "                 Summary_prep  \\\n",
       "0              cough medicine   \n",
       "1                fresh greasy   \n",
       "2  strawberry twizzlers yummy   \n",
       "\n",
       "                                           Text_prep  \n",
       "0  look secret ingredient robitussin believe find...  \n",
       "1  good flavor come securely pack fresh delicious...  \n",
       "2  strawberry twizzlers guilty pleasure yummy six...  "
      ]
     },
     "metadata": {},
     "execution_count": 15
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 57029 entries, 0 to 57502\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Score         57029 non-null  int64 \n",
      " 1   Summary       57029 non-null  object\n",
      " 2   Text          57029 non-null  object\n",
      " 3   Summary_prep  57029 non-null  object\n",
      " 4   Text_prep     57029 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 2.6+ MB\n",
      "\n",
      " Shape of data (57029, 5)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# Check the cleaned text\r\n",
    "import random\r\n",
    "loc = random.randint(0, len(df_new))\r\n",
    "print('Original text...')\r\n",
    "print(list(df_new.loc[loc, ['Text']]))\r\n",
    "print('Cleaned text...')\r\n",
    "print(list(df_new.loc[loc, ['Text_prep']]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Original text...\n",
      "['Cats loved these \"greenies\".  They know when I\\'m opening the package and come running.  Also the shipper didn\\'t waste any time getting this out to me!  Thanks!!']\n",
      "Cleaned text...\n",
      "['cat love greenies know open package come run also shipper didn waste time get thank']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# Check number of words\r\n",
    "train_string = ' '.join(df_new['Text_prep'])\r\n",
    "splits = train_string.split() \r\n",
    "print('Number of words (punctuation included):', len(splits))\r\n",
    "print('Number of unique words(punct included):', len(set(splits)))\r\n",
    "\r\n",
    "# Check the most common words\r\n",
    "freq_splits = FreqDist(splits)\r\n",
    "print('_'*80)\r\n",
    "print('20 most common words \\n', freq_splits.most_common(20), '\\n')\r\n",
    "\r\n",
    "# Shortest words\r\n",
    "print('_'*80)\r\n",
    "print(\"Shortest words\")\r\n",
    "short = set(s for s in splits if len(s)<4)\r\n",
    "short = [(s, freq_splits[s]) for s in short]\r\n",
    "short.sort(key=lambda x:x[1], reverse=True)\r\n",
    "short[0:5]\r\n",
    "\r\n",
    "#Longest words \r\n",
    "print('_'*80)\r\n",
    "print(\"Longest words \\n\")\r\n",
    "long = set(s for s in splits if len(s)>15)\r\n",
    "long = [(s, freq_splits[s]) for s in long]\r\n",
    "long.sort(key=lambda x:x[1], reverse=True)\r\n",
    "long[0:10]\r\n",
    "\r\n",
    "# Find hltml tags\r\n",
    "find_pattern(r'/?>?w*<|/>', splits, freq_splits)\r\n",
    "\r\n",
    "# Find numbers\r\n",
    "find_pattern(r'\\d', splits, freq_splits)\r\n",
    "\r\n",
    "# Find Hyphenated words\r\n",
    "find_pattern(r'\\w+-+\\w+', splits, freq_splits)\r\n",
    "\r\n",
    "# Find 'href=' patterns\r\n",
    "find_pattern(r'href\\=', splits, freq_splits)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of words (punctuation included): 2325128\n",
      "Number of unique words(punct included): 40169\n",
      "________________________________________________________________________________\n",
      "20 most common words \n",
      " [('like', 28666), ('taste', 26252), ('flavor', 21769), ('good', 20160), ('get', 18601), ('love', 18589), ('one', 17768), ('make', 17541), ('try', 17082), ('coffee', 16581), ('great', 16558), ('use', 16412), ('buy', 15644), ('tea', 15274), ('product', 14528), ('food', 14104), ('find', 13568), ('eat', 13028), ('would', 12630), ('dog', 10892)] \n",
      "\n",
      "________________________________________________________________________________\n",
      "Shortest words\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('get', 18601),\n",
       " ('one', 17768),\n",
       " ('try', 17082),\n",
       " ('use', 16412),\n",
       " ('buy', 15644)]"
      ]
     },
     "metadata": {},
     "execution_count": 17
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "________________________________________________________________________________\n",
      "Longest words \n",
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('gastrointestinal', 24),\n",
       " ('enthusiastically', 20),\n",
       " ('strawberrybanana', 15),\n",
       " ('vitaminsminerals', 8),\n",
       " ('indistinguishable', 8),\n",
       " ('misrepresentation', 7),\n",
       " ('sucralosesplenda', 5),\n",
       " ('itchingbitinglicking', 5),\n",
       " ('hexametaphosphate', 5),\n",
       " ('dogfoodanalysiscom', 5)]"
      ]
     },
     "metadata": {},
     "execution_count": 17
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 words matched, which is 0.00% of total\n",
      "Sample of patterns searched [] \n",
      "\n",
      "0 words matched, which is 0.00% of total\n",
      "Sample of patterns searched [] \n",
      "\n",
      "0 words matched, which is 0.00% of total\n",
      "Sample of patterns searched [] \n",
      "\n",
      "0 words matched, which is 0.00% of total\n",
      "Sample of patterns searched [] \n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# Check number of words (for feature Summary)\r\n",
    "train_string = ' '.join(df_new['Summary_prep'])\r\n",
    "splits = train_string.split() \r\n",
    "print('Number of words (punctuation included):', len(splits))\r\n",
    "print('Number of unique words(punct included):', len(set(splits)))\r\n",
    "\r\n",
    "# Check the most common words\r\n",
    "freq_splits = FreqDist(splits)\r\n",
    "print('_'*80)\r\n",
    "print('20 most common words \\n', freq_splits.most_common(20), '\\n')\r\n",
    "\r\n",
    "# Shortest words\r\n",
    "print('_'*80)\r\n",
    "print(\"Shortest words\")\r\n",
    "short = set(s for s in splits if len(s)<4)\r\n",
    "short = [(s, freq_splits[s]) for s in short]\r\n",
    "short.sort(key=lambda x:x[1], reverse=True)\r\n",
    "short[0:5]\r\n",
    "\r\n",
    "#Longest words \r\n",
    "print('_'*80)\r\n",
    "print(\"Longest words \\n\")\r\n",
    "long = set(s for s in splits if len(s)>15)\r\n",
    "long = [(s, freq_splits[s]) for s in long]\r\n",
    "long.sort(key=lambda x:x[1], reverse=True)\r\n",
    "long[0:10]\r\n",
    "\r\n",
    "# Find hltml tags\r\n",
    "find_pattern(r'/?>?w*<|/>', splits, freq_splits)\r\n",
    "\r\n",
    "# Find numbers\r\n",
    "find_pattern(r'\\d', splits, freq_splits)\r\n",
    "\r\n",
    "# Find Hyphenated words\r\n",
    "find_pattern(r'\\w+-+\\w+', splits, freq_splits)\r\n",
    "\r\n",
    "# Find 'href=' patterns\r\n",
    "find_pattern(r'href\\=', splits, freq_splits)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of words (punctuation included): 165819\n",
      "Number of unique words(punct included): 10095\n",
      "________________________________________________________________________________\n",
      "20 most common words \n",
      " [('great', 7491), ('good', 5139), ('love', 3986), ('best', 3412), ('taste', 3069), ('coffee', 2627), ('tea', 2438), ('dog', 2219), ('product', 1945), ('delicious', 1901), ('flavor', 1681), ('like', 1527), ('food', 1482), ('cat', 1367), ('excellent', 1308), ('price', 1165), ('tasty', 1164), ('yummy', 1111), ('treat', 1090), ('snack', 1018)] \n",
      "\n",
      "________________________________________________________________________________\n",
      "Shortest words\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('tea', 2438), ('dog', 2219), ('cat', 1367), ('cup', 828), ('buy', 609)]"
      ]
     },
     "metadata": {},
     "execution_count": 18
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "________________________________________________________________________________\n",
      "Longest words \n",
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('tastingeffective', 3),\n",
       " ('misrepresentation', 2),\n",
       " ('chemicalspreservatives', 2),\n",
       " ('thebestcoffeeever', 2),\n",
       " ('strawberrybanana', 2),\n",
       " ('makingvanillacom', 1),\n",
       " ('bresaolabundnerfleish', 1),\n",
       " ('alphisnumberonefan', 1),\n",
       " ('sebclarityconnectcom', 1),\n",
       " ('lovelovelovelove', 1)]"
      ]
     },
     "metadata": {},
     "execution_count": 18
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 words matched, which is 0.00% of total\n",
      "Sample of patterns searched [] \n",
      "\n",
      "0 words matched, which is 0.00% of total\n",
      "Sample of patterns searched [] \n",
      "\n",
      "0 words matched, which is 0.00% of total\n",
      "Sample of patterns searched [] \n",
      "\n",
      "0 words matched, which is 0.00% of total\n",
      "Sample of patterns searched [] \n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Split into train test set**\r\n",
    "\r\n",
    "Next, we will split the cleaned data into train (90%) and test set(10%). We will take 20% of the train data to be validation set. Here we shouldn't use random split as usual, since our score column contains mostly 5 stars ratings. We should instead split the train and test set accordingly to the column Score."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "y = df_new['Score'].astype('category')\r\n",
    "df_text = df_new.drop(['Score'], axis=1)\r\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_text, y, stratify=y, \r\n",
    "                                                    test_size=0.1, random_state=0)\r\n",
    "# Reset index for train data\r\n",
    "x_train.reset_index(inplace=True, drop=True)\r\n",
    "y_train = y_train.reset_index(drop=True)\r\n",
    "\r\n",
    "# Create validation set\r\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, stratify=y_train, \r\n",
    "                                                test_size=0.2, random_state=0)\r\n",
    "\r\n",
    "# Reset index for train data\r\n",
    "x_train.reset_index(inplace=True, drop=True)\r\n",
    "y_train = y_train.reset_index(drop=True)\r\n",
    "\r\n",
    "# Reset index for val data\r\n",
    "x_val.reset_index(inplace=True, drop=True)\r\n",
    "y_val = y_val.reset_index(drop=True)\r\n",
    "\r\n",
    "# Reset index for test data\r\n",
    "x_test.reset_index(inplace=True, drop=True)\r\n",
    "y_test = y_test.reset_index(drop=True)\r\n",
    "\r\n",
    "\r\n",
    "# Check distribution of Score in y_train / y_test\r\n",
    "plt.figure(figsize=(5, 5))\r\n",
    "sns.countplot(y_train, color='blue', alpha=0.5, label='train data')\r\n",
    "sns.countplot(y_test, color='red', alpha=0.5, label='test data')\r\n",
    "plt.legend()\r\n",
    "plt.title('Number of observations in each Score category')\r\n",
    "plt.show();"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f9a673e93f8648d2b5d4752faa103a4d"
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\ttran\\Anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# Export train, val and test set\r\n",
    "df_train.to_csv(repo+'/train.csv', encoding='utf-8', index=False)\r\n",
    "y_train.to_csv(repo+'/train_labels.csv', encoding='utf-8', index=False)\r\n",
    "\r\n",
    "df_val.to_csv(repo+'/valid.csv', encoding='utf-8', index=False)\r\n",
    "y_val.to_csv(repo+'/valid_labels.csv', encoding='utf-8', index=False)\r\n",
    "\r\n",
    "df_test.to_csv(repo+'/test.csv', encoding='utf-8', index=False)\r\n",
    "y_test.to_csv(repo+'/test_labels.csv', encoding='utf-8', index=False)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'df_train' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_34552/3361352586.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Export train, val and test set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepo\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'/train.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepo\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'/train_labels.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf_val\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepo\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'/valid.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_train' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "interpreter": {
   "hash": "e88734949cfad01e9c9daf169f31362e2053d91cee716e8faab2b799a4f82d3c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}